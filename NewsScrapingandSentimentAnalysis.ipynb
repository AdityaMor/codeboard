{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               CHOOSE A CATEGORY\n",
      "1. Top News\n",
      "2. World\n",
      "3. Entertainment\n",
      "4. Sports\n",
      "5. Technology\n",
      "6. Opinions\n",
      "7. EXIT\n",
      "6\n",
      "SUBJECTIVITY\n",
      " __________\n",
      "Subjective\n",
      "\n",
      "SENTIMENT\n",
      "__________\n",
      "\n",
      "POSITIVE\n",
      "\n",
      "DATE\n",
      "_______\n",
      " 06 Dec 2019 02:46:23 GMT\n",
      "\n",
      "HEADLINE\n",
      "__________\n",
      "The importance of learning in the early years\n",
      "\n",
      "DESCRIPTION\n",
      "____________\n",
      "If children enter school without requisite competencies, learning gaps develop early and grow over time\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.hindustantimes.com/rf/image_size_630x354/HT/p2/2019/12/04/Pictures/children-cheering-in-classroom_5f68f058-1674-11ea-ba57-c3a9d68be36c.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     FULL STORY LINK\n",
      "                      _____________\n",
      "https://www.hindustantimes.com/analysis/the-importance-of-learning-in-the-early-years/story-i1BIFZYzct4hXP3NOnmNPM.html\n",
      "\n",
      "\n",
      "2\n",
      "SUBJECTIVITY\n",
      " __________\n",
      "Objective\n",
      "\n",
      "SENTIMENT\n",
      "__________\n",
      "\n",
      "NEUTRAL\n",
      "\n",
      "DATE\n",
      "_______\n",
      " 06 Dec 2019 09:30:19 GMT\n",
      "\n",
      "HEADLINE\n",
      "__________\n",
      "US Speaker directs drafting of articles of impeachment against Donald Trump\n",
      "\n",
      "DESCRIPTION\n",
      "____________\n",
      "Pelosiâ€™s announcement advances the impeachment process rapidly towards a vote in the House of Representatives before Christmas.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://www.hindustantimes.com/rf/image_size_630x354/HT/p2/2019/12/05/Pictures/nato-alliance-summit-in-watford_d2a45434-1789-11ea-8601-f2d8bfbcf79c.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     FULL STORY LINK\n",
      "                      _____________\n",
      "https://www.hindustantimes.com/world-news/us-speaker-directs-drafting-of-articles-of-impeachment-against-donald-trump/story-UqZ7B4X84lE06i3VQcDSvK.html\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## to input url \n",
    "import requests \n",
    "#to parse through the RSS(Rich Site Summary)\n",
    "import xml.etree.ElementTree as ET\n",
    "#to process textual data\n",
    "from textblob import TextBlob\n",
    "#to display an image \n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "#this is to prevent overloading of the server during scraping\n",
    "import time\n",
    "#This is to use the randomise the reviews\n",
    "import random\n",
    "#this is to import the movie review dataset\n",
    "from nltk.corpus import movie_reviews\n",
    "#This is to create a basic classifier\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "random.seed(1)\n",
    "\n",
    "\n",
    "\n",
    "#function to load the data \n",
    "def loadRSS(): \n",
    "\n",
    "\n",
    "    resp = requests.get(RSS_FEED_URL) \n",
    "\n",
    "\n",
    "    return resp.content \n",
    "\n",
    "\n",
    "\n",
    "#function to parse through the \n",
    "def parseXML(rss): \n",
    "#create element tree\n",
    "    root = ET.fromstring(rss) \n",
    "\n",
    "#creating empty list \n",
    "    newsitems = [] \n",
    "\n",
    "\n",
    "    for item in root.findall('./channel/item'):\n",
    "#creating a dictionary to store the content\n",
    "        news = {} \n",
    "        \n",
    "\n",
    "\n",
    "        for child in item: \n",
    "\n",
    "            #using namespace which is already defined in the rss feed \n",
    "            if child.tag == '{http://search.yahoo.com/mrss/}content': \n",
    "                news['media'] = child.attrib['url']\n",
    "            #working with all the other child tag in the element tree    \n",
    "            else: \n",
    "                news[child.tag] = child.text\n",
    "        #appending the news in the dictionary        \n",
    "        newsitems.append(news) \n",
    "\n",
    "\n",
    "    return newsitems \n",
    "\n",
    "def topStories(): \n",
    "\n",
    "    rss = loadRSS() \n",
    "\n",
    "\n",
    "    newsitems = parseXML(rss) \n",
    "    return newsitems\n",
    "def subjectivity(str):\n",
    "    z=TextBlob(str)\n",
    "    \n",
    "    if z.sentiment.subjectivity > 0:\n",
    "            \n",
    "            return 'Subjective'\n",
    "    elif z.sentiment.subjectivity == 0: \n",
    "            return 'Objective'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def improvement(str):\n",
    "    p = tf_train[y_train==1].sum(0) + 1\n",
    "\n",
    "    q = tf_train[y_train==0].sum(0) + 1\n",
    "    #the log count ratio\n",
    "    r = np.log((p/p.sum()) / (q/q.sum()))\n",
    "    b = np.log(len(p) / len(q))\n",
    "    #normal linear regression\n",
    "    pre_preds = tf_test @ r.T + b\n",
    "    preds = pre_preds.T > 0\n",
    "    accuracy = (preds == y_test).mean()\n",
    "    #using tfidf vectorizer (term frequency inverse document frequency)from the document class using this to imporove accuracy\n",
    "    #using n gram as well with this model\n",
    "    \n",
    "    vect = TfidfVectorizer(strip_accents='unicode', tokenizer=tokenize, ngram_range=(1, 2), max_df=0.9, min_df=3, sublinear_tf=True)\n",
    "    tfidf_train = vect.fit_transform(X_train)\n",
    "    tfidf_test = vect.transform(X_test)\n",
    "\n",
    "def sentiment(str):\n",
    "        train = [\n",
    "        ('I love this sandwich.', 'pos'),\n",
    "\n",
    "        ]\n",
    "        test = [\n",
    "            ('The beer was good.', 'pos'),\n",
    "\n",
    "        ]\n",
    "\n",
    "        cl = NaiveBayesClassifier(train)\n",
    "\n",
    "        # Grab some movie review data\n",
    "        reviews = [(list(movie_reviews.words(fileid)), category)\n",
    "                      for category in movie_reviews.categories()\n",
    "                      for fileid in movie_reviews.fileids(category)]\n",
    "        random.shuffle(reviews)\n",
    "        new_train, new_test = reviews[0:800], reviews[801:1000]\n",
    "\n",
    "\n",
    "        # Update the classifier with the new training data\n",
    "        cl.update(new_train)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = cl.accuracy(test + new_test)\n",
    "        \n",
    "        ###TO PRINT ACCURACY OF THE CLASSIFIER\n",
    "        #print(accuracy)\n",
    "\n",
    "        ###Show 5 most informative features\n",
    "        \n",
    "        #cl.show_informative_features(5)\n",
    "\n",
    "\n",
    "        # create TextBlob object of passed text \n",
    "        analysis = TextBlob(str)\n",
    "        \n",
    "        # set sentiment\n",
    "        print()\n",
    "\n",
    "        if analysis.sentiment.polarity > 0:\n",
    "            \n",
    "            return 'POSITIVE'\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return 'NEUTRAL'\n",
    "        else: \n",
    "            return 'NEGATIVE'\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def displayd(li):\n",
    "            for i in range(0,1):\n",
    "                    #to get the required title from the dictionary of information returned \n",
    "                    f=str(li[i].get(\"title\"))\n",
    "                    print(\"SUBJECTIVITY\")\n",
    "                    print(\" __________\" )\n",
    "                    print(subjectivity(f))\n",
    "                    print()\n",
    "                    \n",
    "\n",
    "                               #to print the sentiment of the news\n",
    "                    print(\"SENTIMENT\")\n",
    "                    print(\"__________\" )\n",
    "                    print(sentiment(f))\n",
    "                    print()\n",
    "                    #test.append((f,sentiment(f)))\n",
    "\n",
    "\n",
    "                    print(\"DATE\")\n",
    "                    print(\"_______\" )\n",
    "\n",
    "                    q=str(li[i].get(\"pubDate\"))\n",
    "                    print(q[4:len(q)-1])\n",
    "                    print()\n",
    "\n",
    "                    print(\"HEADLINE\")\n",
    "                    print(\"__________\" )\n",
    "\n",
    "                    #to get the required title from the dictionary of information returned \n",
    "                    f=str(li[i].get(\"title\"))\n",
    "                    #this is done to split the sting and remove all the special characters\n",
    "                    print(f)\n",
    "                    print()\n",
    "                    print('DESCRIPTION')\n",
    "                    print(\"____________\" )\n",
    "\n",
    "                    x=str(li[i].get(\"description\"))\n",
    "                    print(x)\n",
    "\n",
    "\n",
    "                    t=str(li[i].get(\"media\"))\n",
    "                    \n",
    "\n",
    "\n",
    "                    Image(url= t)\n",
    "                    display(Image(url= t))\n",
    "                 \n",
    "                    print('                     FULL STORY LINK')\n",
    "                    print(\"                 \"+\"     _____________\" )\n",
    "                    s=str(li[i].get(\"link\"))\n",
    "                    print(s)\n",
    "                    print()\n",
    "                    print()\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                    \n",
    "print(\"               CHOOSE A CATEGORY\")\n",
    "print(\"1. Top News\")\n",
    "print(\"2. World\")\n",
    "print(\"3. Entertainment\")\n",
    "print(\"4. Sports\")\n",
    "print(\"5. Technology\")\n",
    "print(\"6. Opinions\")\n",
    "print(\"7. EXIT\")\n",
    "\n",
    "\n",
    "\n",
    "#To choose various news items \n",
    "n=int(input())\n",
    "flag=True\n",
    "while flag==True:\n",
    "    if n==1:\n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/topnews/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "\n",
    "        n=int(input())\n",
    "    elif n==2:\n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/world/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "\n",
    "        n=int(input())\n",
    "\n",
    "    elif n==3:\n",
    "        \n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/entertainment/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "        n=int(input())\n",
    "    elif n==4:\n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/sports/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "        n=int(input())\n",
    "\n",
    "    elif n==5:\n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/tech/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "\n",
    "        n=int(input())\n",
    "    elif n==6:\n",
    "        RSS_FEED_URL=\"https://www.hindustantimes.com/rss/opinion/rssfeed.xml\"\n",
    "        li=(topStories())\n",
    "        displayd(li)\n",
    "\n",
    "        n=int(input())\n",
    "    elif n==7:\n",
    "        flag=False\n",
    "    else:\n",
    "        print(\"Invalid Operation\")\n",
    "        n=int(input())\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
